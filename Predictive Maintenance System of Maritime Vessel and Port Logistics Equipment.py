# -*- coding: utf-8 -*-
"""Predictive Maintenance System of Maritime Vessel and Port Logistics Equipment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hbQYL9ZPDoMi5wS-JJFNQAd8P8i_th7T

# Data Preprocessing and Model Building

## Naval Vessel

### Turbine and Compressor
"""

import pandas as pd
data = pd.read_csv("/content/Naval Vessel.csv")

data.drop("index", axis = 1, inplace = True)
data.head()

data.describe()

data.info()

data.isnull().sum().sum()

data.duplicated().sum()

unique_values = data.nunique()
print(unique_values)

data.columns = data.columns.str.strip()
data.columns

import matplotlib.pyplot as plt
import seaborn as sns

df = data.copy()
df.drop(["GT Compressor inlet air temperature (T1) [C]","GT Compressor inlet air pressure (P1) [bar]"], axis = 1, inplace = True)
corr_matrix = df.corr()

plt.figure(figsize=(20, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

data.shape

import warnings
warnings.filterwarnings('ignore')

df = data.copy()

plt.figure(figsize=(20,12))
for i, col in enumerate(df):
    plt.subplot(5, 4, i + 1)
    sns.boxplot(y=df[col], palette='Set2')
    plt.title(f'Boxplot of {col}')
    plt.ylabel('Values')
    plt.tight_layout()
plt.tight_layout()
plt.show()

import warnings
warnings.filterwarnings('ignore')

df = data.copy()

plt.figure(figsize=(20,12))
for i, col in enumerate(df.columns):
    plt.subplot(5, 4, i + 1)
    sns.histplot(df[col], kde=True, color='skyblue', stat='density')
    plt.title(f'KDE & Histogram of {col}')
    plt.ylabel('Frequency')
    plt.xlabel('Values')
    plt.tight_layout()

plt.tight_layout()
plt.show()

import warnings
warnings.filterwarnings('ignore')

df = data.copy()

target_column = "GT Turbine decay state coefficient"
columns = df.columns

plt.figure(figsize=(25, 20))

plot_number = 1

for i, col in enumerate(columns):
    if col != target_column:
        plt.subplot((len(columns) - 1) // 3 + 1, 3, plot_number)
        sns.regplot(x=col, y=target_column, data=df, color='skyblue', scatter_kws={'alpha': 0.5})
        plt.title(f'{col} vs {target_column}')
        plt.xlabel(col)
        plt.ylabel(target_column)
        plot_number += 1

plt.tight_layout()
plt.show()

import warnings
warnings.filterwarnings('ignore')

df = data.copy()

target_column = "GT Compressor decay state coefficient"
columns = df.columns

plt.figure(figsize=(25, 20))

plot_number = 1

for i, col in enumerate(columns):
    if col != target_column:
        plt.subplot((len(columns) - 1) // 3 + 1, 3, plot_number)
        sns.regplot(x=col, y=target_column, data=df, color='skyblue', scatter_kws={'alpha': 0.5})
        plt.title(f'{col} vs {target_column}')
        plt.xlabel(col)
        plt.ylabel(target_column)
        plot_number += 1

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler, Normalizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score

def load_and_clean_data(filepath):
    data = pd.read_csv(filepath)

    data.drop("index", axis=1, inplace=True)

    data.columns = data.columns.str.strip()

    rename_columns = {
        'Lever position': 'lever_position',
        'Ship speed (v)': 'ship_speed_v',
        'Gas Turbine (GT) shaft torque (GTT) [kN m]': 'gt_shaft_torque_knm',
        'GT rate of revolutions (GTn) [rpm]': 'gt_rate_of_revolutions_rpm',
        'Gas Generator rate of revolutions (GGn) [rpm]': 'gg_rate_of_revolutions_rpm',
        'Starboard Propeller Torque (Ts) [kN]': 'starboard_propeller_torque_knm',
        'Port Propeller Torque (Tp) [kN]': 'port_propeller_torque_knm',
        'Hight Pressure (HP) Turbine exit temperature (T48) [C]': 'hp_turbine_exit_temp_c',
        'GT Compressor inlet air temperature (T1) [C]': 'gt_compressor_inlet_air_temp_c',
        'GT Compressor outlet air temperature (T2) [C]': 'gt_compressor_outlet_air_temp_c',
        'HP Turbine exit pressure (P48) [bar]': 'hp_turbine_exit_pressure_bar',
        'GT Compressor inlet air pressure (P1) [bar]': 'gt_compressor_inlet_air_pressure_bar',
        'GT Compressor outlet air pressure (P2) [bar]': 'gt_compressor_outlet_air_pressure_bar',
        'GT exhaust gas pressure (Pexh) [bar]': 'gt_exhaust_gas_pressure_bar',
        'Turbine Injecton Control (TIC) [%]': 'turbine_injection_control_pct',
        'Fuel flow (mf) [kg/s]': 'fuel_flow_kg_s',
        'GT Compressor decay state coefficient': 'gt_compressor_decay_state_coeff',
        'GT Turbine decay state coefficient': 'gt_turbine_decay_state_coeff'
    }

    data.rename(columns=rename_columns, inplace=True)
    return data

def preprocess_data(data):
    x = data.drop(['gt_compressor_decay_state_coeff', 'gt_turbine_decay_state_coeff'], axis=1)
    scaler = StandardScaler()
    x_scaled = scaler.fit_transform(x)
    x_normalized = Normalizer().fit_transform(x_scaled)

    return x_normalized

def train_and_evaluate(x, y):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)

    linear_model = LinearRegression()
    decision_tree_model = DecisionTreeRegressor(random_state=0)
    random_forest_model = RandomForestRegressor(random_state=0)

    linear_model.fit(x_train, y_train)
    decision_tree_model.fit(x_train, y_train)
    random_forest_model.fit(x_train, y_train)

    linear_metrics = calculate_metrics(linear_model, x_test, y_test)
    decision_tree_metrics = calculate_metrics(decision_tree_model, x_test, y_test)
    random_forest_metrics = calculate_metrics(random_forest_model, x_test, y_test)

    results_df = pd.DataFrame({
        'Model': ['Linear Regression', 'Decision Tree', 'Random Forest'],
        'R² Score': [linear_metrics[3], decision_tree_metrics[3], random_forest_metrics[3]],
        'MSE': [linear_metrics[0], decision_tree_metrics[0], random_forest_metrics[0]],
        'MAE': [linear_metrics[1], decision_tree_metrics[1], random_forest_metrics[1]],
        'MAPE': [linear_metrics[2], decision_tree_metrics[2], random_forest_metrics[2]],
    })

    return results_df

def calculate_metrics(model, x_test, y_test):
    predictions = model.predict(x_test)
    mse = mean_squared_error(y_test, predictions)
    mae = mean_absolute_error(y_test, predictions)
    mape = mean_absolute_percentage_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    return mse, mae, mape, r2

# Execution
data = load_and_clean_data("/content/Naval Vessel.csv")

x_normalized = preprocess_data(data)

results_compressor = train_and_evaluate(x_normalized, data['gt_compressor_decay_state_coeff'])
results_turbine = train_and_evaluate(x_normalized, data['gt_turbine_decay_state_coeff'])

print("Results for GT Compressor Decay State Coefficient:")
print(results_compressor)

print("\nResults for GT Turbine Decay State Coefficient:")
print(results_turbine)

"""## AGV

### Servometer
"""

import pandas as pd
data = pd.read_csv("/content/servomotor.csv")

data.head()

data.describe()

data.info()

from sklearn.preprocessing import LabelEncoder
enc = LabelEncoder()
for i in data.columns:
    if data[i].dtype == 'object':
        data[i]=enc.fit_transform(data[i])
data.info()

data.isnull().sum().sum()

data.duplicated().sum()

unique_values = data.nunique()
print(unique_values)

import matplotlib.pyplot as plt
import seaborn as sns

df = data.copy()
corr_matrix = df.corr()

plt.figure(figsize=(20, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

import warnings
warnings.filterwarnings('ignore')

plt.figure(figsize=(10,6))
for i, col in enumerate(df):
    plt.subplot(2,3, i + 1)
    sns.boxplot(y=df[col], palette='Set2')
    plt.title(f'Boxplot of {col}')
    plt.ylabel('Values')
    plt.tight_layout()
plt.tight_layout()
plt.show()

import warnings
warnings.filterwarnings('ignore')

df = data.copy()

plt.figure(figsize=(10,6))
for i, col in enumerate(df.columns):
    plt.subplot(2,3, i + 1)
    sns.histplot(df[col], kde=True, color='skyblue', stat='density')
    plt.title(f'KDE & Histogram of {col}')
    plt.ylabel('Frequency')
    plt.xlabel('Values')
    plt.tight_layout()

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def load_and_preprocess_data(filepath):
    data = pd.read_csv(filepath)
    X = data.drop('Class', axis=1)
    y = data['Class']
    categorical_features = ['Motor', 'Screw']
    numerical_features = ['Pgain', 'Vgain']
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numerical_features),
            ('cat', OneHotEncoder(), categorical_features)])

    return X, y, preprocessor

def build_and_evaluate_models(X, y, preprocessor):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

    models = {
        'Linear Regression': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', LinearRegression())
        ]),
        'Decision Tree': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', DecisionTreeRegressor(random_state=0))
        ]),
        'Random Forest': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', RandomForestRegressor(random_state=0))
        ]),
        'K-Nearest Neighbors': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', KNeighborsRegressor())
        ]),
        'Gradient Boosting': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', GradientBoostingRegressor(random_state=0))
        ]),
        'XGBoost': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', XGBRegressor(eval_metric='mlogloss'))
        ])
    }

    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        results[name] = {
            'MSE': mse,
            'MAE': mae,
            'R² Score': r2
        }
    return results

# Main execution
X, y, preprocessor = load_and_preprocess_data("/content/servomotor.csv")
results = build_and_evaluate_models(X, y, preprocessor)

# Results
for model_name, metrics in results.items():
    print(f"Results for {model_name}:")
    print(f"MSE: {metrics['MSE']:.4f}")
    print(f"MAE: {metrics['MAE']:.4f}")
    print(f"R² Score: {metrics['R² Score']:.4f}")
    print("\n")

"""### Battery"""

import pandas as pd
data = pd.read_csv("/content/Battery_RUL.csv")

data.head()

data.describe()

data.info()

data.isnull().sum().sum()

data.duplicated().sum()

unique_values = data.nunique()
print(unique_values)

import matplotlib.pyplot as plt
import seaborn as sns

df = data.copy()
corr_matrix = df.corr()

plt.figure(figsize=(20, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

import warnings
warnings.filterwarnings('ignore')

plt.figure(figsize=(10,6))
for i, col in enumerate(df):
    plt.subplot(3,3, i + 1)
    sns.boxplot(y=df[col], palette='Set2')
    plt.title(f'Boxplot of {col}')
    plt.ylabel('Values')
    plt.tight_layout()
plt.tight_layout()
plt.show()

data.shape

numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns
numerical_columns = numerical_columns.drop('RUL')

def remove_outliers_iqr(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_filtered = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df_filtered

for col in numerical_columns:
    data = remove_outliers_iqr(data, col)

data.shape

import warnings
warnings.filterwarnings('ignore')

df = data.copy()

plt.figure(figsize=(10,6))
for i, col in enumerate(df.columns):
    plt.subplot(3,3, i + 1)
    sns.histplot(df[col], kde=True, color='skyblue', stat='density')
    plt.title(f'KDE & Histogram of {col}')
    plt.ylabel('Frequency')
    plt.xlabel('Values')
    plt.tight_layout()

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def load_and_preprocess_data(filepath):
    data = pd.read_csv(filepath)

    X = data.drop('RUL', axis=1)
    y = data['RUL']

    numerical_features = X.columns.tolist()

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numerical_features)
        ])

    return X, y, preprocessor

def build_and_evaluate_models(X, y, preprocessor):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

    models = {
        'Linear Regression': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', LinearRegression())
        ]),
        'Decision Tree': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', DecisionTreeRegressor(random_state=0))
        ]),
        'Random Forest': Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('regressor', RandomForestRegressor(random_state=0))
        ])
    }

    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        results[name] = {
            'MSE': mse,
            'MAE': mae,
            'R² Score': r2
        }

    return results

# Main execution
X, y, preprocessor = load_and_preprocess_data("/content/Battery_RUL.csv")
results = build_and_evaluate_models(X, y, preprocessor)

# Results
for model_name, metrics in results.items():
    print(f"Results for {model_name}:")
    print(f"MSE: {metrics['MSE']:.4f}")
    print(f"MAE: {metrics['MAE']:.4f}")
    print(f"R² Score: {metrics['R² Score']:.4f}")
    print("\n")

"""### Bearings"""

# !unzip -q {'/content/drive/MyDrive/DataScience/bearing_signals.zip'} -d {'/content/drive/MyDrive/DataScience/bearing_signals.csv'}

import pandas as pd

data_signals = pd.read_csv("/content/drive/MyDrive/DataScience/bearing_signals.csv/bearing_signals copy.csv")
data_classes = pd.read_csv("/content/bearing_classes.csv")

print(data_signals.shape)
print(data_classes.shape)

data_signals = data_signals.sample(n=1000, random_state=42)

data_signals

data_classes

!pip install pyspark

from pyspark.sql import SparkSession
import pandas as pd

spark = SparkSession.builder.appName("Bearing Signals").getOrCreate()

data_signals_pd = pd.read_csv("/content/drive/MyDrive/DataScience/bearing_signals.csv/bearing_signals copy.csv", nrows=1000)
data_classes_pd = pd.read_csv("/content/bearing_classes.csv", nrows=1000)

data_signals_spark = spark.createDataFrame(data_signals_pd)
data_classes_spark = spark.createDataFrame(data_classes_pd)

data_signals_spark.createOrReplaceTempView("data_signals")
data_classes_spark.createOrReplaceTempView("data_classes")

query = """
SELECT s.*, c1.status AS bearing_1_status, c2.status AS bearing_2_status
FROM data_signals s
LEFT JOIN data_classes c1 ON s.bearing_1_id = c1.bearing_id
LEFT JOIN data_classes c2 ON s.bearing_2_id = c2.bearing_id
"""

data = spark.sql(query)

data.show()

from pyspark.sql.functions import col, when, count, isnull

data.printSchema()

missing_values = data.select([count(when(col(c).isNull(), c)).alias(c) for c in data.columns])

from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.feature import VectorAssembler, StandardScaler

assembler = VectorAssembler(inputCols=['a1_x', 'a1_y', 'a1_z', 'a2_x', 'a2_y', 'a2_z', 'rpm', 'hz', 'w'], outputCol='features')
assembled_data = assembler.transform(data)

scaler = StandardScaler(inputCol='features', outputCol='scaled_features')
scaler_model = scaler.fit(assembled_data)
scaled_data = scaler_model.transform(assembled_data)

final_data_bearing_1 = scaled_data.select(['scaled_features', 'bearing_1_status'])
final_data_bearing_2 = scaled_data.select(['scaled_features', 'bearing_2_status'])

(training_data_bearing_1, test_data_bearing_1) = final_data_bearing_1.randomSplit([0.7, 0.3], seed=42)
(training_data_bearing_2, test_data_bearing_2) = final_data_bearing_2.randomSplit([0.7, 0.3], seed=42)

lr_bearing_1 = LogisticRegression(labelCol='bearing_1_status', featuresCol='scaled_features')
dt_bearing_1 = DecisionTreeClassifier(labelCol='bearing_1_status', featuresCol='scaled_features')
rf_bearing_1 = RandomForestClassifier(labelCol='bearing_1_status', featuresCol='scaled_features')

lr_bearing_2 = LogisticRegression(labelCol='bearing_2_status', featuresCol='scaled_features')
dt_bearing_2 = DecisionTreeClassifier(labelCol='bearing_2_status', featuresCol='scaled_features')
rf_bearing_2 = RandomForestClassifier(labelCol='bearing_2_status', featuresCol='scaled_features')

lr_model_bearing_1 = lr_bearing_1.fit(training_data_bearing_1)
dt_model_bearing_1 = dt_bearing_1.fit(training_data_bearing_1)
rf_model_bearing_1 = rf_bearing_1.fit(training_data_bearing_1)

lr_model_bearing_2 = lr_bearing_2.fit(training_data_bearing_2)
dt_model_bearing_2 = dt_bearing_2.fit(training_data_bearing_2)
rf_model_bearing_2 = rf_bearing_2.fit(training_data_bearing_2)

lr_predictions_bearing_1 = lr_model_bearing_1.transform(test_data_bearing_1)
dt_predictions_bearing_1 = dt_model_bearing_1.transform(test_data_bearing_1)
rf_predictions_bearing_1 = rf_model_bearing_1.transform(test_data_bearing_1)

lr_predictions_bearing_2 = lr_model_bearing_2.transform(test_data_bearing_2)
dt_predictions_bearing_2 = dt_model_bearing_2.transform(test_data_bearing_2)
rf_predictions_bearing_2 = rf_model_bearing_2.transform(test_data_bearing_2)

evaluator_bearing_1 = MulticlassClassificationEvaluator(labelCol='bearing_1_status', predictionCol='prediction', metricName='accuracy')

lr_accuracy_bearing_1 = evaluator_bearing_1.evaluate(lr_predictions_bearing_1)
dt_accuracy_bearing_1 = evaluator_bearing_1.evaluate(dt_predictions_bearing_1)
rf_accuracy_bearing_1 = evaluator_bearing_1.evaluate(rf_predictions_bearing_1)

evaluator_bearing_2 = MulticlassClassificationEvaluator(labelCol='bearing_2_status', predictionCol='prediction', metricName='accuracy')

lr_accuracy_bearing_2 = evaluator_bearing_2.evaluate(lr_predictions_bearing_2)
dt_accuracy_bearing_2 = evaluator_bearing_2.evaluate(dt_predictions_bearing_2)
rf_accuracy_bearing_2 = evaluator_bearing_2.evaluate(rf_predictions_bearing_2)

print(f"Logistic Regression Accuracy for bearing_1_status: {lr_accuracy_bearing_1:.4f}")
print(f"Decision Tree Accuracy for bearing_1_status: {dt_accuracy_bearing_1:.4f}")
print(f"Random Forest Accuracy for bearing_1_status: {rf_accuracy_bearing_1:.4f}")

print(f"Logistic Regression Accuracy for bearing_2_status: {lr_accuracy_bearing_2:.4f}")
print(f"Decision Tree Accuracy for bearing_2_status: {dt_accuracy_bearing_2:.4f}")
print(f"Random Forest Accuracy for bearing_2_status: {rf_accuracy_bearing_2:.4f}")

"""  # **Predictive Maintenance System of Maritime Vessel and Port Logistics Equipment**"""

!pip install pyspark

import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler, Normalizer, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from pyspark.sql import SparkSession
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import StandardScaler as SparkStandardScaler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator



# Naval Vessel
# Turbine and Compressor
class BaseModel:
    def __init__(self, filepath):
        self.data = self.load_and_clean_data(filepath)
        self.x = self.preprocess_data(self.data)

    def load_and_clean_data(self, filepath):
        data = pd.read_csv(filepath)
        data.drop("index", axis=1, inplace=True)
        data.columns = data.columns.str.strip()

        rename_columns = {
            'Lever position': 'lever_position',
            'Ship speed (v)': 'ship_speed_v',
            'Gas Turbine (GT) shaft torque (GTT) [kN m]': 'gt_shaft_torque_knm',
            'GT rate of revolutions (GTn) [rpm]': 'gt_rate_of_revolutions_rpm',
            'Gas Generator rate of revolutions (GGn) [rpm]': 'gg_rate_of_revolutions_rpm',
            'Starboard Propeller Torque (Ts) [kN]': 'starboard_propeller_torque_knm',
            'Port Propeller Torque (Tp) [kN]': 'port_propeller_torque_knm',
            'Hight Pressure (HP) Turbine exit temperature (T48) [C]': 'hp_turbine_exit_temp_c',
            'GT Compressor inlet air temperature (T1) [C]': 'gt_compressor_inlet_air_temp_c',
            'GT Compressor outlet air temperature (T2) [C]': 'gt_compressor_outlet_air_temp_c',
            'HP Turbine exit pressure (P48) [bar]': 'hp_turbine_exit_pressure_bar',
            'GT Compressor inlet air pressure (P1) [bar]': 'gt_compressor_inlet_air_pressure_bar',
            'GT Compressor outlet air pressure (P2) [bar]': 'gt_compressor_outlet_air_pressure_bar',
            'GT exhaust gas pressure (Pexh) [bar]': 'gt_exhaust_gas_pressure_bar',
            'Turbine Injecton Control (TIC) [%]': 'turbine_injection_control_pct',
            'Fuel flow (mf) [kg/s]': 'fuel_flow_kg_s',
            'GT Compressor decay state coefficient': 'gt_compressor_decay_state_coeff',
            'GT Turbine decay state coefficient': 'gt_turbine_decay_state_coeff'
        }

        data.rename(columns=rename_columns, inplace=True)
        return data

    def preprocess_data(self, data):
        x = data.drop(['gt_compressor_decay_state_coeff', 'gt_turbine_decay_state_coeff'], axis=1)
        scaler = StandardScaler()
        x_scaled = scaler.fit_transform(x)
        x_normalized = Normalizer().fit_transform(x_scaled)
        return x_normalized

    def train_and_evaluate_decision_tree(self, x, y):
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)

        decision_tree_model = DecisionTreeRegressor(random_state=0)
        decision_tree_model.fit(x_train, y_train)

        decision_tree_metrics = self.calculate_metrics(decision_tree_model, x_test, y_test)

        results_df = pd.DataFrame({
            'Model': ['Decision Tree'],
            'R² Score': [decision_tree_metrics[0]],
            'MSE': [decision_tree_metrics[1]],
            'MAE': [decision_tree_metrics[2]],
            'RSME': [decision_tree_metrics[3]],
            'MAPE': [decision_tree_metrics[4]]
        })

        return results_df

    def calculate_metrics(self, model, x_test, y_test):
        predictions = model.predict(x_test)
        mse = mean_squared_error(y_test, predictions)
        mae = mean_absolute_error(y_test, predictions)
        mape = mean_absolute_percentage_error(y_test, predictions)
        rsme = mean_squared_error(y_test, predictions, squared=False)
        r2 = r2_score(y_test, predictions)
        return r2, mse, mae, rsme, mape

class Compressor(BaseModel):
    def __init__(self, filepath):
        super().__init__(filepath)
        self.results = self.train_and_evaluate_decision_tree(self.x, self.data['gt_compressor_decay_state_coeff'])

    def display_results(self):
        print("")
        print("Compressor Model Results:")
        print(self.results)

class Turbine(BaseModel):
    def __init__(self, filepath):
        super().__init__(filepath)
        self.results = self.train_and_evaluate_decision_tree(self.x, self.data['gt_turbine_decay_state_coeff'])

    def display_results(self):
        print("")
        print("Turbine Model Results:")
        print(self.results)



# AGVs -
# Servomotor
class Servomotor:
    def __init__(self, filepath):
        self.filepath = filepath
        self.X, self.y, self.preprocessor = self.load_and_preprocess_data()
        self.pipeline = self.create_pipeline()

    def load_and_preprocess_data(self):
        data = pd.read_csv(self.filepath)
        X = data.drop('Class', axis=1)
        y = data['Class']
        categorical_features = ['Motor', 'Screw']
        numerical_features = ['Pgain', 'Vgain']
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_features),
                ('cat', OneHotEncoder(), categorical_features)
            ]
        )
        return X, y, preprocessor

    def create_pipeline(self):
        return Pipeline(steps=[
            ('preprocessor', self.preprocessor),
            ('regressor', RandomForestRegressor(
                n_estimators=100,
                max_depth=20,
                min_samples_split=2,
                min_samples_leaf=1,
                bootstrap=True,
                random_state=0
            ))
        ])

    def train_and_evaluate(self):
        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=0)

        self.pipeline.fit(X_train, y_train)
        y_pred = self.pipeline.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        mape = mean_absolute_percentage_error(y_test, y_pred)
        rmse = mean_squared_error(y_test, y_pred, squared=False)

        return self.display_results('Random Forest', r2, mse, mae, mape, rmse)

    def display_results(self, model_name, r2, mse, mae, mape, rmse):
        results_df = pd.DataFrame({
        'Model': [model_name],
        'R² Score': [r2],
        'MSE': [mse],
        'MAE': [mae],
        'RSME': [rmse],
        'MAPE': [mape]})
        print("")
        print(f"Servomotor Model Results:")
        print(results_df)


# Battery
class Battery:
    def __init__(self, filepath):
        self.filepath = filepath
        self.X, self.y, self.preprocessor = self.load_and_preprocess_data()
        self.model = self.create_pipeline()

    def load_and_preprocess_data(self):
        data = pd.read_csv(self.filepath)
        X = data.drop('RUL', axis=1)
        y = data['RUL']
        numerical_features = X.columns.tolist()
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_features)
            ]
        )
        return X, y, preprocessor

    def create_pipeline(self):
        return Pipeline(steps=[
            ('preprocessor', self.preprocessor),
            ('regressor', LinearRegression())
        ])

    def train_and_evaluate(self):
        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=0)
        self.model.fit(X_train, y_train)
        y_pred = self.model.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        mape = mean_absolute_percentage_error(y_test, y_pred)
        rmse = mean_squared_error(y_test, y_pred, squared=False)

        results = {
        'Model': 'Linear Regression',
        'R² Score': r2,
        'MSE': mse,
        'MAE': mae,
        'RSME': rmse,
        'MAPE': mape
    }
        return results


    def display_results(self, results):
        print("")
        print(f"Battery Model Results:")
        results_df = pd.DataFrame([results])
        print(results_df)




# Bearings 1 and 2
class BearingModel:
    def __init__(self, signal_path, class_path):
        self.spark = SparkSession.builder.appName("Bearing Signals").getOrCreate()
        self.signal_path = signal_path
        self.class_path = class_path
        self.load_data()
        self.process_data()
        self.train_models()
        self.evaluate_models()

    def load_data(self):
        data_signals = pd.read_csv(self.signal_path).sample(n=1000, random_state=42)
        data_classes = pd.read_csv(self.class_path)
        self.data_signals_spark = self.spark.createDataFrame(data_signals)
        self.data_classes_spark = self.spark.createDataFrame(data_classes)
        self.data_signals_spark.createOrReplaceTempView("data_signals")
        self.data_classes_spark.createOrReplaceTempView("data_classes")

    def process_data(self):
        query = """
        SELECT s.*, c1.status AS bearing_1_status, c2.status AS bearing_2_status
        FROM data_signals s
        LEFT JOIN data_classes c1 ON s.bearing_1_id = c1.bearing_id
        LEFT JOIN data_classes c2 ON s.bearing_2_id = c2.bearing_id
        """
        data = self.spark.sql(query)
        assembler = VectorAssembler(inputCols=['a1_x', 'a1_y', 'a1_z', 'a2_x', 'a2_y', 'a2_z', 'rpm', 'hz', 'w'], outputCol='features')
        assembled_data = assembler.transform(data)
        scaler = SparkStandardScaler(inputCol='features', outputCol='scaled_features')
        scaler_model = scaler.fit(assembled_data)
        scaled_data = scaler_model.transform(assembled_data)
        self.final_data_bearing_1 = scaled_data.select(['scaled_features', 'bearing_1_status'])
        self.final_data_bearing_2 = scaled_data.select(['scaled_features', 'bearing_2_status'])

    def train_models(self):
        (self.training_data_bearing_1, self.test_data_bearing_1) = self.final_data_bearing_1.randomSplit([0.7, 0.3], seed=42)
        (self.training_data_bearing_2, self.test_data_bearing_2) = self.final_data_bearing_2.randomSplit([0.7, 0.3], seed=42)
        self.lr_bearing_1 = LogisticRegression(labelCol='bearing_1_status', featuresCol='scaled_features')
        self.lr_bearing_2 = LogisticRegression(labelCol='bearing_2_status', featuresCol='scaled_features')
        self.lr_model_bearing_1 = self.lr_bearing_1.fit(self.training_data_bearing_1)
        self.lr_model_bearing_2 = self.lr_bearing_2.fit(self.training_data_bearing_2)

    def evaluate_models(self):
        lr_predictions_bearing_1 = self.lr_model_bearing_1.transform(self.test_data_bearing_1)
        lr_predictions_bearing_2 = self.lr_model_bearing_2.transform(self.test_data_bearing_2)
        evaluator_bearing_1 = MulticlassClassificationEvaluator(labelCol='bearing_1_status', predictionCol='prediction', metricName='accuracy')
        evaluator_bearing_2 = MulticlassClassificationEvaluator(labelCol='bearing_2_status', predictionCol='prediction', metricName='accuracy')
        self.accuracy_bearing_1 = evaluator_bearing_1.evaluate(lr_predictions_bearing_1)
        self.accuracy_bearing_2 = evaluator_bearing_2.evaluate(lr_predictions_bearing_2)

    def get_accuracy_bearing_1(self):
        return self.accuracy_bearing_1

    def get_accuracy_bearing_2(self):
        return self.accuracy_bearing_2

def battery():
    filepath = "/content/Battery_RUL.csv"
    battery_analysis = Battery(filepath)
    results = battery_analysis.train_and_evaluate()
    battery_analysis.display_results(results)

def bearing1(model):
    accuracy_bearing_1 = model.get_accuracy_bearing_1()
    print("")
    print(f"Bearing1's Logistic Regression Results: \n{accuracy_bearing_1:.4f}")

def bearing2(model):
    accuracy_bearing_2 = model.get_accuracy_bearing_2()
    print("")
    print(f"Bearing2's Logistic Regression Results: \n{accuracy_bearing_2:.4f}")

def servomotor():
    filepath = "/content/servomotor.csv"
    servomotor_analysis = Servomotor(filepath)
    servomotor_analysis.train_and_evaluate()


def turbine():
    filepath = "/content/Naval Vessel.csv"

    turbine_model = Turbine(filepath)
    turbine_model.display_results()

def compressor():
    filepath = "/content/Naval Vessel.csv"

    compressor_model = Compressor(filepath)
    compressor_model.display_results()

print("Predictive Maintenance of Vessel and Port Equipment")
print("-------------------------------------------------------")
print("Naval Vessel Parts:")
compressor()
turbine()
print("")
print("")
print("")
print("Automated Guided Vehicle Parts:")
battery()
servomotor()
model = BearingModel("/content/drive/MyDrive/DataScience/bearing_signals.csv/bearing_signals copy.csv", "/content/bearing_classes.csv")
bearing1(model)
bearing2(model)